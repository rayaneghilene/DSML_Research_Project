{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data preprocessing for Hate speech detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Citation**\n",
    "@inproceedings{chung-etal-2019-conan,\n",
    "    title = \"{CONAN} - {CO}unter {NA}rratives through Nichesourcing: a Multilingual Dataset of Responses to Fight \n",
    "    #Online Hate Speech\",\n",
    "    author = \"Chung, Yi-Ling and Kuzmenko, Elizaveta and Tekiroglu, Serra Sinem and Guerini, Marco\",\n",
    "    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n",
    "    month = jul,\n",
    "    year = \"2019\",\n",
    "    address = \"Florence, Italy\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://www.aclweb.org/anthology/P19-1271\",\n",
    "    doi = \"10.18653/v1/P19-1271\",\n",
    "    pages = \"2819--2829\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2023.10.3 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_hub\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn_id</th>\n",
       "      <th>hateSpeech</th>\n",
       "      <th>counterSpeech</th>\n",
       "      <th>hsType</th>\n",
       "      <th>hsSubType</th>\n",
       "      <th>cnType</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>educationLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENT1ST0001HS0033CN000021</td>\n",
       "      <td>According to a recent OFSTED report, a school ...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
       "      <td>In Birmingham there is a school where girls an...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
       "      <td>A school in Birningham is still separating gir...</td>\n",
       "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENT1ST0001HS0033CN000022</td>\n",
       "      <td>According to a recent OFSTED report, a school ...</td>\n",
       "      <td>While this story is presented as an 'Islamic i...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
       "      <td>In Birmingham there is a school where girls an...</td>\n",
       "      <td>While this story is presented as an 'Islamic i...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>crimes</td>\n",
       "      <td>facts</td>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        cn_id  \\\n",
       "0    ENT1ST0001HS0033CN000021   \n",
       "1  ENT1ST0001HS0033CN000021P1   \n",
       "2  ENT1ST0001HS0033CN000021P2   \n",
       "3    ENT1ST0001HS0033CN000022   \n",
       "4  ENT1ST0001HS0033CN000022P1   \n",
       "\n",
       "                                          hateSpeech  \\\n",
       "0  According to a recent OFSTED report, a school ...   \n",
       "1  In Birmingham there is a school where girls an...   \n",
       "2  A school in Birningham is still separating gir...   \n",
       "3  According to a recent OFSTED report, a school ...   \n",
       "4  In Birmingham there is a school where girls an...   \n",
       "\n",
       "                                       counterSpeech        hsType hsSubType  \\\n",
       "0  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
       "1  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
       "2  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
       "3  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
       "4  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
       "\n",
       "  cnType   age gender educationLevel  \n",
       "0  facts  61.0   male       Bachelor  \n",
       "1  facts  61.0   male       Bachelor  \n",
       "2  facts  61.0   male       Bachelor  \n",
       "3  facts  61.0   male       Bachelor  \n",
       "4  facts  61.0   male       Bachelor  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing and reading the dataset\n",
    "read_data = pd.read_csv('/workspaces/CONAN/CONAN/CONAN.csv')\n",
    "df = read_data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Islamophobia']\n",
      "Index(['cn_id', 'hateSpeech', 'counterSpeech', 'hsType', 'hsSubType', 'cnType',\n",
      "       'age', 'gender', 'educationLevel'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print distinct values in column'hsType'\n",
    "print(df['hsType'].unique())\n",
    "#print all columns in the dataset\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset Conan.csv only contains islamophobia related hate speech data and it's counterSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14988 entries, 0 to 14987\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   cn_id           14988 non-null  object \n",
      " 1   hateSpeech      14988 non-null  object \n",
      " 2   counterSpeech   14988 non-null  object \n",
      " 3   hsType          14988 non-null  object \n",
      " 4   hsSubType       14988 non-null  object \n",
      " 5   cnType          14988 non-null  object \n",
      " 6   age             12207 non-null  float64\n",
      " 7   gender          12207 non-null  object \n",
      " 8   educationLevel  12207 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 1.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [101, 4372, 2102, 2487, 3367, 8889, 24096, 789...\n",
      "1    [101, 4372, 2102, 2487, 3367, 8889, 24096, 789...\n",
      "2    [101, 4372, 2102, 2487, 3367, 8889, 24096, 789...\n",
      "3    [101, 4372, 2102, 2487, 3367, 8889, 24096, 789...\n",
      "4    [101, 4372, 2102, 2487, 3367, 8889, 24096, 789...\n",
      "Name: text_tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the text data\n",
    "df['text_tokens'] = df['cn_id'].apply(lambda text: tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=512))\n",
    "print(df['text_tokens'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Padding and Truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        101\n",
       "1        101\n",
       "2        101\n",
       "3        101\n",
       "4        101\n",
       "        ... \n",
       "14983    101\n",
       "14984    101\n",
       "14985    101\n",
       "14986    101\n",
       "14987    101\n",
       "Name: text_tokens, Length: 14988, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "max_seq_length = 128\n",
    "# Convert the 'text_tokens' column from a list of integers to PyTorch tensors\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda x: torch.tensor(x))\n",
    "# Ensure all sequences are of the same length\n",
    "df['text_tokens'] = pad_sequences(df['text_tokens'], maxlen=max_seq_length, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "df['text_tokens']\n",
    "\n",
    "# Set the maximum sequence length\n",
    "\n",
    "# Pad or truncate the sequences\n",
    "#df['text_tokens'] = pad_sequences(df['text_tokens'], maxlen=max_seq_length, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "# print some tokenized sentences\n",
    "#df['text_tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hate speech encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['hateSpeech'] = label_encoder.fit_transform(df['hateSpeech'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cn_id</th>\n",
       "      <th>hateSpeech</th>\n",
       "      <th>counterSpeech</th>\n",
       "      <th>hsType</th>\n",
       "      <th>hsSubType</th>\n",
       "      <th>cnType</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>educationLevel</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>ITT1ST0019HS0010CN000943</td>\n",
       "      <td>173</td>\n",
       "      <td>Anche gli Italiani violentano, che si fa, ci c...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>rapism</td>\n",
       "      <td>hypocrisy</td>\n",
       "      <td>37.0</td>\n",
       "      <td>male</td>\n",
       "      <td>High school</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>ENT1ST0008HS0053CN000445P1</td>\n",
       "      <td>613</td>\n",
       "      <td>Define western society? Who chooses this?</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>culture</td>\n",
       "      <td>question</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Master</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>ENT1ST0012HS0032CN000548P2</td>\n",
       "      <td>244</td>\n",
       "      <td>Many Muslims aren't homophobic and sexist, but...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>culture , women</td>\n",
       "      <td>facts</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>FRT1ST0014HS0038CN000996P2</td>\n",
       "      <td>354</td>\n",
       "      <td>Avez vous étudiez l'islam?</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>generic</td>\n",
       "      <td>question</td>\n",
       "      <td>34.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>ITT1ST0013HS0013CN000287T1</td>\n",
       "      <td>729</td>\n",
       "      <td>I do not think there is anything that can conf...</td>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>economics</td>\n",
       "      <td>denouncing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            cn_id  hateSpeech  \\\n",
       "14472    ITT1ST0019HS0010CN000943         173   \n",
       "820    ENT1ST0008HS0053CN000445P1         613   \n",
       "1643   ENT1ST0012HS0032CN000548P2         244   \n",
       "7530   FRT1ST0014HS0038CN000996P2         354   \n",
       "11851  ITT1ST0013HS0013CN000287T1         729   \n",
       "\n",
       "                                           counterSpeech        hsType  \\\n",
       "14472  Anche gli Italiani violentano, che si fa, ci c...  Islamophobia   \n",
       "820            Define western society? Who chooses this?  Islamophobia   \n",
       "1643   Many Muslims aren't homophobic and sexist, but...  Islamophobia   \n",
       "7530                          Avez vous étudiez l'islam?  Islamophobia   \n",
       "11851  I do not think there is anything that can conf...  Islamophobia   \n",
       "\n",
       "             hsSubType      cnType   age  gender educationLevel  text_tokens  \n",
       "14472           rapism   hypocrisy  37.0    male    High school          101  \n",
       "820            culture    question  25.0    male         Master          101  \n",
       "1643   culture , women       facts  21.0  female         Master          101  \n",
       "7530           generic    question  34.0    male       Bachelor          101  \n",
       "11851        economics  denouncing   NaN     NaN            NaN          101  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print a snippet of thetraining dataset\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Loader and Batch Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(torch.tensor(train_df['text_tokens'].tolist()), torch.tensor(train_df['hateSpeech'].tolist()))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "        101, 101, 101, 101])\n"
     ]
    }
   ],
   "source": [
    "# print input_ids of the first batch\n",
    "data = next(iter(train_loader))\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fine-Tuning BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/CONAN/DSML Research Project/Datapreprocessing.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbug-free-spork-r56vw57xg49hxg4q/workspaces/CONAN/DSML%20Research%20Project/Datapreprocessing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m input_ids, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbug-free-spork-r56vw57xg49hxg4q/workspaces/CONAN/DSML%20Research%20Project/Datapreprocessing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bbug-free-spork-r56vw57xg49hxg4q/workspaces/CONAN/DSML%20Research%20Project/Datapreprocessing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbug-free-spork-r56vw57xg49hxg4q/workspaces/CONAN/DSML%20Research%20Project/Datapreprocessing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bbug-free-spork-r56vw57xg49hxg4q/workspaces/CONAN/DSML%20Research%20Project/Datapreprocessing.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1564\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[1;32m   1565\u001b[0m     input_ids,\n\u001b[1;32m   1566\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1567\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1568\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1569\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1570\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1571\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1572\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1573\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1574\u001b[0m )\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[1;32m   1578\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:969\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    968\u001b[0m \u001b[39melif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m    970\u001b[0m     input_shape \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39msize()\n\u001b[1;32m    971\u001b[0m \u001b[39melif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/modeling_utils.py:3941\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   3938\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   3940\u001b[0m \u001b[39m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[0;32m-> 3941\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id \u001b[39min\u001b[39;00m input_ids[:, [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]]:\n\u001b[1;32m   3942\u001b[0m     warn_string \u001b[39m=\u001b[39m (\n\u001b[1;32m   3943\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3944\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3946\u001b[0m     )\n\u001b[1;32m   3948\u001b[0m     \u001b[39m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define lists to store training and validation metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Fine-tune the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    train_losses.append(total_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {train_losses[-1]:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_true_labels = []\n",
    "    val_predicted_labels = []\n",
    "    val_total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, labels = batch\n",
    "            outputs = model(input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "            labels = labels.cpu().numpy()\n",
    "            predicted = predicted.cpu().numpy()\n",
    "\n",
    "            val_true_labels.extend(labels)\n",
    "            val_predicted_labels.extend(predicted)\n",
    "            val_total_loss += loss.item()\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(val_true_labels, val_predicted_labels)\n",
    "    val_losses.append(val_total_loss / len(val_loader))\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Validation Loss: {val_losses[-1]:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(\"path_to_save_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# Lists to store the true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "val_data = TensorDataset(torch.tensor(val_df['text_tokens'].tolist()), torch.tensor(val_df['hateSpeech'].tolist()))\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, labels = batch\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "        # Get predicted labels\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        # Convert tensors to numpy arrays\n",
    "        labels = labels.cpu().numpy()\n",
    "        predicted = predicted.cpu().numpy()\n",
    "\n",
    "        # Append true and predicted labels to the lists\n",
    "        true_labels.extend(labels)\n",
    "        predicted_labels.extend(predicted)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "roc_auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
